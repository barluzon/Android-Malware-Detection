import pickle

import feature_ext
import pandas as pd
import numpy as np
import json
import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns

# Set pandas to show all columns when you print a dataframe
pd.set_option('display.max_columns', None)

fe = feature_ext.feature_ext()
fe.ext_features()
# Global setting here you choose the dataset number and classification type for the model
json_file = "../tests.json"

# Read the json and read it to a pandas dataframe object, you can change these settings
with open(json_file) as file:
    raw_ds = json.load(file)
df = pd.json_normalize(raw_ds, max_level=2)

for column in df.columns[df.isna().any()].tolist():
    df[column] = df[column].fillna(0)

# Iterate through the data set and check if there is column that contains one value
from collections import Counter


def non_unique_features(dataframe):
    same_value_features = []
    for column in dataframe.columns:
        if column != 'label':
            if column != 'sha256':
                if len(Counter(dataframe[column])) == 1:
                    same_value_features.append(column)
    return same_value_features


#feat_to_delete = non_unique_features(df)
#print('feat_to_delete:', feat_to_delete)

#df = df.drop(feat_to_delete, axis=1)
df.drop('sha256', axis=1, inplace=True)

from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, classification_report
from collections import Counter


def vectorize_df(df):
    le = LabelEncoder()
    for column in df.columns:
        df[column] = le.fit_transform(df[column].astype(str))
    return df

#best1000_features/best3000_features/best10000_features
with open("select_features/best10000_features.txt", "r") as features_txt:
    new_list = features_txt.readlines()
features_list = [element.replace('\n', '') for element in new_list]

print('df list len before:',len(df.columns))
for col in features_list:
    if col not in df.columns:
        df[col] = 0
print('df list len after:',len(df.columns))


dataset = vectorize_df(df)
dataset = dataset[features_list]
#Choose sec_svm_model_1000/sec_svm_model_3000/sec_svm_model_10000
clf = pickle.load(open('models/sec_svm_model_10000.pkl', 'rb'))
X = dataset[features_list].to_numpy()
# Predict with your model
pred = clf.predict(X)
predictions = []
for i in pred:
    predictions.append(i)
label = None
if predictions[0] == 0:
    label = 'Benign'
else:
    label = 'Malware'
print('The model predicted the file as:', predictions, '(',label,')')
